#!/bin/bash
# Job name:
#################################
#SBATCH --job-name=REPLACE_JOB_NAME
#
# Account:
#SBATCH --account=co_aiolos ## << this is the condo that tina bought // could also use fc_anemos#
#SBATCH --partition=savio3
#
#SBATCH --nodes=2
# Wall clock limit (let's set to 10 mintes, 0 seconds)
#SBATCH --time=01:00:00
#SBATCH -o REPLACE_WORKING_DIRECTORY/slurm-stdout # STDOUT

## Commands to run
cd REPLACE_WORKING_DIRECTORY       

echo "Cleaning up directory..." 
rm *.log
rm GRIBFILE*

# Load in modules 
module purge 
module load intel/2016.4.072
module load openmpi/3.0.1-intel
module load cmake/3.22.0 
module unload openmpi/2.0.2-intel
module list 

######### UNGRIB ############
# Set up + run ungrib
echo "Linking grib files to directory..."
./link_grib.csh REPLACE_GRIB_FILE_PATH

echo "Linking HRR-SMOKE VTABLE...."
ln -sf ungrib/Variable_Tables/Vtable.hrrr_smoke.rap Vtable

echo -e "\tRunning ungrib..."
./ungrib.exe >> ungrib.out 

######### GEOGRID ############
echo -e "\tRunning geogrid ..."
./geogrid.exe >>  geogrid.out          

######### METGRID ############
echo -e "\tRunning metgrid ..."
./metgrid.exe >> metgrid.out

######### REAL ############
echo -e "\tRunning real ..."
echo "Starting loop." > real.out

hour0=REPLACE_START_HOUR
hourF=23
DATE=REPLACE_DATE

source activate geo_env 

for hour in $(seq $hour0 $hourF); do

  echo "Writing namelist.input for T0=$hour" >> real.out
  date="${DATE}_${hour}:00:00"
  sed -r -i.bak s/"start_hour[[:space:]]*=[[:space:]]*[[:digit:]]*,"/"start_hour= ${hour},"/g namelist.input
  end_hour=$((${hour} + 1))
  sed -r -i.bak s/"end_hour[[:space:]]*=[[:space:]]*[[:digit:]]*,"/"end_hour= ${hour},"/g namelist.input

  echo "Running real..."    >> real.out
  ./real2018.exe   >> real.out

  # Rename the output WRF input file to have the date appended.
  mv wrfinput_d01 wrfinput_d01_$date

  
  ## COPY OVER SMOKE TO THE OUTPUT! ## 
cat << EOF > ./add_massden_as_PM25.py
import xarray as xr

# Metgrid 
path = '${met_fn}'
data = xr.open_dataset(path)

# WRFINPUT 
path = '${wrf_fn}'
data_out = xr.open_dataset(path)

# Now we try some substitution trickery
smoke_var_name = 'PM2_5_DRY'
data_out[smoke_var_name] = data_out.T.copy(deep=True)

# Correct the units + description
data_out[smoke_var_name].attrs['units'] = 'ug/m3' # UNITS = ug/m3! 
data_out[smoke_var_name].attrs['description'] = data['MASSDEN'].attrs['description']

vertical_layers = data_out.bottom_top

for i in vertical_layers:
  data_out[smoke_var_name][dict(bottom_top=i)] = data['MASSDEN'][dict(num_metgrid_levels=i)] 
  # We need to index array of data rather than use isel / sel. found this out the hard way.

data_out.to_netcdf('${wrf_fn}.nc')
EOF

  echo "running python" >> real.out
  conda run -n geo_env python ./add_massden_as_PM25.py  >> real.out
  
done

echo "Done with REAL"

######### CLEAN UP! ############

# Create stdout for this processing run
stdout=REPLACE_JOB_NAME.out
echo ungrib.out   >  $stdout
echo geogrid.out  >> $stdout
echo metgrid.out  >> $stdout
echo real.out     >> $stdout 

echo "Done processing grib file, wrfinput[s] created." 

#rm *.p000
#rm GRIBFILE.*
